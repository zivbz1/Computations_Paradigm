{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize_Decision_Making_Data\n",
    "\n",
    "### This script takes raw JSON data from the decision-making phase of the paradigm and organizes it for all participants and all trials.\n",
    "\n",
    "#### Created by: Nachshon Korem & Ziv Ben-Zion \n",
    "#### Last Updated:May 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Relevant Packages\n",
    "\n",
    "# Pandas is a package for data manipulation, analysis, and visualization (pd is a short name)\n",
    "import pandas as pd \n",
    "\n",
    "# NumPy (Numerical Python) is a package for scientific computing, data analysis, and numerical computations (np is a short name)\n",
    "import numpy as np\n",
    "\n",
    "# JSON (JavaScript Object Notation) is a package for encoding and decoding data in JSON format\n",
    "import json\n",
    "\n",
    "# Glob is a package which takes a string pattern and returns a list of filenames that match that pattern\n",
    "from glob import glob\n",
    "\n",
    "# OS (Operating System) is a package providing a way to interact with the operating system that Python is running on\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the data all of the subjects\n",
    "sublist = glob('C:\\\\Users\\\\zhb4\\\\Box Sync\\\\Neural Computations\\\\Online Pilot\\\\Raw Data\\\\study_result_*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a function used to extract a single subject data based on its JSON file and subject number\n",
    " \n",
    "def extract_sub_data(res, sub): \n",
    "    '''\n",
    "    Input: \n",
    "    res- data extracted from JSON for a single subject\n",
    "    sub- string representing the subject number\n",
    "    Outupt\n",
    "    df- pandas DataFrame containing the extracted data.\n",
    "    '''   \n",
    "    # creating an empty dataframe\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "# The function loops through each trial in the res data and extracts relevant pieces of information, including the mean reward\n",
    "#  for each of the two stimuli (stim1 and stim2), the participant's decision (decision) and its reaction time (RT_decision). \n",
    "    for i in range(len(res)):\n",
    "        time = res[i]['time'] #time in Unix timestamp\n",
    "        stim1 = res[i]['cues'][0]['reward_mean'] #learned mean value of stimulus #1\n",
    "        stim2 = res[i]['cues'][1]['reward_mean'] #learned mean value of stimulus #2\n",
    "        decision = res[i]['cues'][2]['chosen_i']+1 # choosing stimulus #1 is \"1\" and choosing stimulus #2 is \"2\"\n",
    "        RT_decision =res[i]['cues'][2]['rt'] #time it took to make a decision (sec)\n",
    "    \n",
    "#  In trials without input we define the rating and their reaction times as NaN (Not a Number)        \n",
    "        if res[i]['cues'][0]['takingInput']==False:\n",
    "            val1, conf1, val2, conf2, RT_val1, RT_conf1, RT_val2, RT_conf2 = np.NaN, np.NaN, np.NaN, np.NaN, np.NaN, np.NaN, np.NaN, np.NaN\n",
    "            conf_decision, RT_conf_decision = np.NaN, np.NaN\n",
    "            \n",
    "#  In trials with input, we also extract participants' value & confidence ratings for each stimulus (val1, val2, conf1, conf2) \n",
    "#  and their reaction times (RT_val1, RT_val2, RT_conf1, RT_conf2), and the confidence in the choice plus the reaction time\n",
    "# (conf_decision), RT_onf_decision)\n",
    "        else:\n",
    "            val1 = res[i]['cues'][0]['input']['rewardLikely_UI']\n",
    "            conf1 = res[i]['cues'][0]['input']['confidence_UI']\n",
    "            RT_val1 = res[i]['cues'][0]['input']['rewardLikely_UI_rt']\n",
    "            RT_conf1 = res[i]['cues'][0]['input']['confidence_UI_rt']\n",
    "\n",
    "            val2 = res[i]['cues'][1]['input']['rewardLikely_UI']\n",
    "            conf2 = res[i]['cues'][1]['input']['confidence_UI']\n",
    "            RT_val2 = res[i]['cues'][1]['input']['rewardLikely_UI_rt']\n",
    "            RT_conf2 = res[i]['cues'][1]['input']['confidence_UI_rt']\n",
    "\n",
    "            conf_decision = res[i]['cues'][2]['input']['confidence_UI']\n",
    "            RT_conf_decision = res[i]['cues'][2]['input']['confidence_UI_rt']\n",
    "\n",
    "# For each trial, the function creates a dictionary with the extracted information and creates a temporary DataFrame. \n",
    "# These temporary DataFrames are concatenated together to create the final DataFrame with all the trials of a single subject.\n",
    "        trial = {'sub': sub, 'time':time, 'trial': i+1, 'stim1': stim1, 'stim2':stim2, 'decision': decision, 'RT_decision': RT_decision,\n",
    "             'val1': val1, 'RT_val1': RT_val1, 'conf1': conf1, 'RT_conf1': RT_conf1, \n",
    "             'val2': val2, 'RT_val2': RT_val2, 'conf2': conf2, 'RT_conf2': RT_conf2,\n",
    "             'conf_decision': conf_decision, 'RT_conf_decision': RT_conf_decision}\n",
    "        temp = pd.DataFrame(trial, index=[0])\n",
    "        df = pd.concat([df, temp])\n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "    df.head()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "#This is used to extract a single subject dataframe based on its JSON file and subject number\n",
    "\n",
    "for folder_path in sublist: \n",
    "    # Specify the subject number\n",
    "    sub = folder_path.split(\"_\")[-1]\n",
    "    # Get the list of items in the subject folder\n",
    "    items = os.listdir(folder_path)\n",
    "    # Filter folders from the list\n",
    "    folders = [item for item in items if os.path.isdir(os.path.join(folder_path, item))]\n",
    "    # Check if there are exactly 13 folders\n",
    "    if len(folders) == 13:\n",
    "        # If so, sort folders alphabetically\n",
    "        sorted_folders = sorted(folders, key=lambda x: int(x.split('_')[1]))\n",
    "        # Retrieve the name of the 8th folder - always the decision-making phase\n",
    "        decision_making_folder = sorted_folders[7]\n",
    "        # Update the folder_path with the name of the 8th folder\n",
    "        folder_path = os.path.join(folder_path, decision_making_folder)\n",
    "        # Open the data.txt file inside the 8th folder and read its contents\n",
    "        data_file_path = os.path.join(folder_path, \"data.txt\")\n",
    "        with open(data_file_path, \"r\") as file:\n",
    "            res = file.read()\n",
    "            #open the JSON file\n",
    "            res = json.loads(res)\n",
    "            #Ignore the beginning and end to take only the data\n",
    "            res = res[1]['data']\n",
    "            #Use the function above \"extract_sub_data\"\n",
    "            temp = extract_sub_data(res, sub)\n",
    "        \n",
    "        #Save the data for one subject and continue to the next \n",
    "        df = pd.concat([df,temp])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining Depression and Anxiety Scores \n",
    "\n",
    "df_PHQ = pd.DataFrame()\n",
    "df_GAD = pd.DataFrame()\n",
    "\n",
    "#This is used to extract a single subject dataframe based on its JSON file and subject number\n",
    "\n",
    "for folder_path in sublist: \n",
    "    # Specify the subject number\n",
    "    sub = folder_path.split(\"_\")[-1]\n",
    "    # Get the list of items in the subject folder\n",
    "    items = os.listdir(folder_path)\n",
    "    # Filter folders from the list\n",
    "    folders = [item for item in items if os.path.isdir(os.path.join(folder_path, item))]\n",
    "    # Check if there are exactly 13 folders\n",
    "    if len(folders) == 13:\n",
    "        # If so, sort folders alphabetically\n",
    "        sorted_folders = sorted(folders, key=lambda x: int(x.split('_')[1]))\n",
    "        # Retrieve the name of the 11th folder - always the PHQ-9 (depression) questionnaire \n",
    "        depression_folder = sorted_folders[10]\n",
    "        # Update the folder_path with the name of the 11th folder\n",
    "        depression_folder_path = os.path.join(folder_path, depression_folder)\n",
    "        # Open the data.txt file inside the 11th folder and read its contents\n",
    "        depression_data_file_path = os.path.join(depression_folder_path, \"data.txt\")\n",
    "        \n",
    "        with open(depression_data_file_path, \"r\") as file:\n",
    "            res = file.read()\n",
    "            #open the JSON file\n",
    "            res = json.loads(res)\n",
    "            #Ignore the beginning and end to take only the data\n",
    "            res = res[0]['response']['P0_Q0']\n",
    "            PHQ9_total = sum(res.values())\n",
    "            #Use the function above \"extract_sub_data\"\n",
    "            temp = {'sub':sub,'PHQ9_total': PHQ9_total}\n",
    "            temp = pd.DataFrame(temp, index=[0])\n",
    "            df_PHQ = pd.concat([df_PHQ, temp])\n",
    "        \n",
    "        # Retrieve the name of the 10th folder - always the GAD-7 (anxiety) questionnaire \n",
    "        anxiety_folder = sorted_folders[9]   \n",
    "        # Update the folder_path with the name of the 10th folder\n",
    "        anxiety_folder_path = os.path.join(folder_path, anxiety_folder)\n",
    "        # Open the data.txt file inside the 10th folder and read its contents\n",
    "        anxiety_data_file_path = os.path.join(anxiety_folder_path, \"data.txt\")\n",
    "        \n",
    "        with open(anxiety_data_file_path, \"r\") as file:\n",
    "            res = file.read()\n",
    "            #open the JSON file\n",
    "            res = json.loads(res)\n",
    "            #Ignore the beginning and end to take only the data\n",
    "            res = res[0]['response']['P0_Q0']\n",
    "            GAD7_total = sum(res.values())\n",
    "            #Use the function above \"extract_sub_data\"\n",
    "            temp = {'sub':sub, 'GAD7_total': GAD7_total}      \n",
    "            temp = pd.DataFrame(temp, index=[0])\n",
    "            df_GAD = pd.concat([df_GAD, temp])\n",
    "#Save the data for one subject and continue to the next \n",
    "df_PHQ = df_PHQ.reset_index(drop=True)\n",
    "df_GAD = df_GAD.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all three dataframes\n",
    "# Merge df and df_PHQ based on a common column\n",
    "clinical_df = pd.merge(df_GAD, df_PHQ, left_on='sub', right_on='sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of trials is 1200\n",
      "The total number of variables per trial is 17\n",
      "The total number of subjects is 40\n"
     ]
    }
   ],
   "source": [
    "#what it the size of the task df? \n",
    "num_trials=df.shape[0]\n",
    "num_variables=df.shape[1]\n",
    "num_subjects=int(df.shape[0]/30)\n",
    "\n",
    "print(f\"The total number of trials is {num_trials}\")\n",
    "print(f\"The total number of variables per trial is {num_variables}\")\n",
    "print(f\"The total number of subjects is {num_subjects}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of subjects is 40\n",
      "The total number of clinical variables per subject is 17\n"
     ]
    }
   ],
   "source": [
    "#what it the size of the clinical df? \n",
    "num_subjects=clinical_df.shape[0]\n",
    "variables=clinical_df.shape[1]\n",
    "\n",
    "print(f\"The total number of subjects is {num_subjects}\")\n",
    "print(f\"The total number of clinical variables per subject is {num_variables}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Decision_Making_Data_40.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_df.to_csv('Clinical_Data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
